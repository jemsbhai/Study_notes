\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}

\author{}
\date{}

\begin{document}

\section{Longitudianl Data Analysis}\label{longitudianl-data-analysis}

\subsubsection{Weighted least-squares (WLS)
estimation}\label{weighted-least-squares-wls-estimation}

\paragraph{(no distribution assumption on
y)}\label{no-distribution-assumption-on-y}

The \textbf{weighted least-squares} estimator of $\boldsymbol{\beta}$,
using a symmetric \emph{weight matrix}, $W$, is the value,
$\tilde{\boldsymbol{\beta}}_W$, which minimize the quadratic form
\[({\bf y}-X\boldsymbol{\beta})'W({\bf y}-X\boldsymbol{\beta}).\]

Standard matrix manipulations give the explicit result
\[\tilde{\boldsymbol{\beta}}_W=(X'WX)^{-1}X'W{\bf y}\] - it's an
unbiased estimator of $\boldsymbol{\beta}$, whatever the choice of $W$.

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $Var(\tilde{\boldsymbol{\beta}}_W)=\sigma^2\{(X'WX)^{-1}X'W\}V\{WX(X'WX)^{-1}\}$.
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  If $W=I$, it reduces to the OLS estimator
  \[\tilde{\boldsymbol{\beta}}_I=(X'X)^{-1}X{\bf y},\] with
  \[Var(\tilde{\boldsymbol{\beta}}_I)=\sigma^2(X'X)^{-1}X'VX(X'X)^{-1}.\]
\item
  If $W=V^{-1}$, the estimator becomes the \emph{MLE} (under the
  assumption of normal dist.), i.e.
  \[\hat{\boldsymbol{\beta}}=(X'V^{-1}X)^{-1}X'V^{-1}{\bf y},\] with
  \[Var(\hat{\boldsymbol{\beta}})=\sigma^2(X'V^{-1}X)^{-1}.\]
\end{enumerate}

\begin{itemize}
\item
  According to the {[}G-M Theorem{]}
  (https://en.wikipedia.org/wiki/Gauss--Markov\_theorem), the MLE is the
  most efficient linear estimator for $\boldsymbol{\beta}$. However, to
  identify this optimal weighting matrix we need to know the complete
  correlation structure of the data -- we don't need to know $\sigma^2$,
  because $\tilde{\boldsymbol{\beta}}_W$ is unchanged by proportional
  changes in all the elements of $W$.
\item
  Also, because the correlation structure may be diffcult to identify in
  practice, it is of interest to ask how much loss of efficiency might
  result from using a different $W$.
\item
  When we know the correlation structure is CS (uniform/exchangable),
  the OLS is fully efficient as the WLS estimator; an intuitive
  explanation is that with a common correlation between any two equally
  spaced measurements on the same unit, there is no reason to weight
  measurements differently.
\end{itemize}

\paragraph{Using OLS estimator is misleading when
$V\ne I$}\label{using-ols-estimator-is-misleading-when-vne-i}

\begin{itemize}
\item
  In many circumstances where there is balanced design, the OLS
  estimator, $\tilde{\boldsymbol{\beta}}$, is perfectly satisfactory for
  point estimation. But this is not always the case. (example in book
  page 63.)
\item
  Even when OLS is reasonably efficient, it is clear from the form of
  \[Var(\tilde{\boldsymbol{\beta}}_I)=\sigma^2(X'X)^{-1}X'VX(X'X)^{-1}\]
  that interval estimation for $\boldsymbol{\beta}$ still requires
  information about $\sigma^2V$, the variance matrix of the data. In
  particular, the usual formula for the variance of the least-squares
  estimator, \[Var(\tilde{\boldsymbol{\beta}})=\sigma^2(X'X)^{-1}\]
  assumes that $V=I$, the identity matrix, and can be seriously
  misleading when this is not so.
\item
  A naive use of OLS would be to ignore the correlation structure in the
  data and to base interval estimation for $\boldsymbol{\beta}$ on the
  variance above with $\sigma^2$ replaced with its usual estimator, the
  residual mean square
  \[\tilde{\sigma}^2=(nm-p)^{-1}({\bf y}-X\tilde{\boldsymbol{\beta}})'({\bf y}-X\tilde{\boldsymbol{\beta}}).\]
  There are two sources of error in this naive approach when $V\ne I$:
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\itemsep1pt\parskip0pt\parsep0pt
\item
  $Var(\tilde{\boldsymbol{\beta}})$ is wrong
\item
  $\tilde{\sigma}^2$ is no longer an unbiased esitmator of $\sigma^2$.
\end{enumerate}

\subsubsection{MLE under Gaussian
assumptions}\label{mle-under-gaussian-assumptions}

\subsubsection{REML}\label{reml}

\paragraph{(under Gaussian
assumptions)}\label{under-gaussian-assumptions}

\end{document}
